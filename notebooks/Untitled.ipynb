{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992e136381374782a88b29634469b99d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "upload_button = widgets.FileUpload()\n",
    "upload_button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "  categories = [\n",
    "        \"Anchor\",\n",
    "        \"Apple\",\n",
    "        \"Baby bottle\",\n",
    "        \"Bomb\",\n",
    "        \"Cactus\",\n",
    "        \"Candle\",\n",
    "        \"Taxi car\",\n",
    "        \"Carrot\",\n",
    "        \"Chess knight\",\n",
    "        \"Clock\",\n",
    "        \"Clown\",\n",
    "        \"Diasy flower\",\n",
    "        \"Dinosaur\",\n",
    "        \"Dolphin\",\n",
    "        \"Dragon\",\n",
    "        \"Exclamation point\",\n",
    "        \"Eye\",\n",
    "        \"Fire\",\n",
    "        \"Four leaf clover\",\n",
    "        \"Ghost\",\n",
    "        \"Green splats\",\n",
    "        \"Hammer\",\n",
    "        \"Heart\",\n",
    "        \"Ice cube\",\n",
    "        \"Igloo\",\n",
    "        \"Key\",\n",
    "        \"Ladybird (Ladybug)\",\n",
    "        \"Light bulb\",\n",
    "        \"Lightning bolt\",\n",
    "        \"Lock\",\n",
    "        \"Maple leaf\",\n",
    "        \"Moon\",\n",
    "        \"No Entry sign\",\n",
    "        \"Orange scarecrow man\",\n",
    "        \"Pencil\",\n",
    "        \"Purple bird\",\n",
    "        \"Purple cat\",\n",
    "        \"Purple dobble hand man\",\n",
    "        \"Red lips\",\n",
    "        \"Scissors\",\n",
    "        \"Skull and crossbones\",\n",
    "        \"Snowflake\",\n",
    "        \"Snowman\",\n",
    "        \"Spider\",\n",
    "        \"Spider’s web\",\n",
    "        \"Sun\",\n",
    "        \"Sunglasses\",\n",
    "        \"Target/crosshairs\",\n",
    "        \"Tortoise\",\n",
    "        \"Treble clef\",\n",
    "        \"Tree\",\n",
    "        \"Water drip\",\n",
    "        \"Dog\",\n",
    "        \"Yin and Yang\",\n",
    "        \"Zebra\",\n",
    "        \"Question mark\",\n",
    "        \"Cheese\",\n",
    "    ]\n",
    "code = list(range(0, len(categories)))\n",
    "category_mapping = dict(zip(code, categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=57, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_location=torch.device('cpu')\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.fc = nn.Linear(512, 57)\n",
    "model.load_state_dict(torch.load('../models/detecting_common_element/neurabble.pth', map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730de1dfa64b4dbb8b0f380f31d96bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe2\\x02\\x1cICC_PROFILE\\x00\\x01\\x01\\x00\\x00\\x02\\x0clcms\\x02\\x10\\x00\\x00mntrRGB XYZ \\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.Image(value=upload_button.data[-1],\n",
    "        width=300,\n",
    "        height=400,\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc216011afa4e07a5fd4b7bf8f4341b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Classify', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classify_button = widgets.Button(description='Classify')\n",
    "classify_button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "valid_tfms = A.Compose([\n",
    "        A.Normalize(mean, std, max_pixel_value=255.0, always_apply=True),\n",
    "        A.Resize(1024,1024, always_apply=True),        \n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_click_classify(b):\n",
    "    img = cv2.imdecode(np.frombuffer(upload_button.data[-1], np.uint8), -1)\n",
    "    img = valid_tfms(image=img)['image']\n",
    "    img = transforms.ToTensor()(img)\n",
    "    prediction = model(img[None, :]).argmax().item()\n",
    "    label_prediction.value = f\"The common element is {category_mapping[prediction]}: \"\n",
    "    \n",
    "classify_button.on_click(on_click_classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7880260a15174e8d98ceb06afeb4425f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Please choose an image')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_prediction = widgets.Label()\n",
    "label_prediction.value = \"Please choose an image\"\n",
    "label_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imdecode(np.frombuffer(upload_button.data[-1], np.uint8), -1)\n",
    "img = valid_tfms(image=img)['image']\n",
    "img = transforms.ToTensor()(img)\n",
    "prediction = model(img[None, :])\n",
    "#f\"The common element is {category_mapping[prediction]}: \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-10.0167,  -8.4024,  -0.0704,  -6.5474,  -9.9440,  -2.6767,  -4.3413,\n",
       "          -6.3616,  -1.1965,  -8.1484,  -3.8291,  -6.5313,  -8.9468,   6.9930,\n",
       "          -1.2129,  -8.2475,  -0.6236,  -6.6813,  -4.6008,  -6.3109,  -7.9400,\n",
       "          -4.1230,   2.1137,  -5.7978,  -6.4784,   5.8218,  -4.6730,  -6.8542,\n",
       "          -9.7918,  -6.2147,  -1.8193,  -5.7984,  -8.5497,   1.1236,  -3.0833,\n",
       "          -2.2935,  -7.1045,   5.7963,  -7.8438,  -2.6374,   2.5117,  -8.8805,\n",
       "          -6.7105,   3.5624,  -2.9445,  -5.3395,  -3.2630,   0.9818,  -8.4334,\n",
       "          -7.9901,  -3.0163,  -5.6868,  -8.7413,  -9.3711,  -7.9345,  -4.1293,\n",
       "         -14.6968]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
